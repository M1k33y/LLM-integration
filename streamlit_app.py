# streamlit_app.py
import os
import streamlit as st
from openai import OpenAI

from app_cli import call_llm
from tools import list_titles

# ---------- Config paginÄƒ ----------
st.set_page_config(page_title="Smart Librarian", page_icon="ğŸ“š", layout="centered")
st.title("ğŸ“š Smart Librarian â€” RAG + Tool Completion")

# ---------- Sidebar: setÄƒri ----------
with st.sidebar:
    st.header("SetÄƒri")
    top_k = st.slider("Top-K RAG", min_value=1, max_value=10, value=5)
    temperature = st.slider("Creativitate (temperature)", 0.0, 1.2, 0.4, 0.1)
    voice_out = st.toggle("ğŸ”Š Voice output (TTS)", value=False)
    st.divider()

    if st.button("ğŸ§¹ Reset chat"):
        st.session_state.chat = []
        st.rerun()

    st.caption(
        "Cheia OpenAI trebuie sÄƒ fie setatÄƒ ca variabilÄƒ de mediu **OPENAI_API_KEY**."
    )
    with st.expander("Titluri disponibile local"):
        st.write(", ".join(list_titles()))

if not os.environ.get("OPENAI_API_KEY"):
    st.warning("OPENAI_API_KEY nu este setatÄƒ Ã®n mediul curent.", icon="âš ï¸")

# ---------- Utilitare ----------
def say(text: str) -> bytes:
    """GenereazÄƒ TTS È™i Ã®ntoarce bytes (mp3). Nu face st.audio aici!"""
    from openai import OpenAI
    client = OpenAI()

    resp = client.audio.speech.create(
        model="gpt-4o-mini-tts",
        voice="alloy",
        input=text,
        response_format="mp3",
    )
    # Ã®n SDK 1.101.0 merge .read() pentru bytes
    return resp.read()

# ---------- Stare chat ----------
if "chat" not in st.session_state:
    st.session_state.chat = []  # list[tuple(role, content)]

# ---------- AfiÈ™eazÄƒ istoric (cronologic, fÄƒrÄƒ dubluri) ----------
for role, content in st.session_state.chat:
    with st.chat_message(role):
        st.markdown(content)

# ---------- Input nou ----------
prompt = st.chat_input("ÃntreabÄƒ despre cÄƒrÈ›i, teme sau cere recomandÄƒriâ€¦")

if prompt:
    # 1) aratÄƒ mesajul curent al utilizatorului (fÄƒrÄƒ sÄƒ-l bagi Ã®ncÄƒ Ã®n istoric)
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2) calculeazÄƒ rÄƒspunsul È™i afiÈ™eazÄƒ-l
    with st.chat_message("assistant"):
        with st.spinner("GÃ¢ndescâ€¦"):
            try:
                answer = call_llm(prompt, top_k=top_k, temperature=temperature)
            except Exception as e:
                answer = f"Eroare: {e}"
        st.markdown(answer)

    # 3) persistÄƒ runda Ã®n istoric È™i reruleazÄƒ aplicaÈ›ia
    st.session_state.chat.append(("user", prompt))
    st.session_state.chat.append(("assistant", answer))
    st.rerun()

if voice_out and st.session_state.chat:
    last_role, last_msg = st.session_state.chat[-1]
    if last_role == "assistant" and last_msg:
        # foloseÈ™te un cache simplu ca sÄƒ nu regenerezi TTS la fiecare rerulare
        key = hash(last_msg)
        if st.session_state.get("tts_key") != key:
            try:
                st.session_state["tts_audio"] = say(last_msg[:1200])  # taie textul dacÄƒ e prea lung
                st.session_state["tts_key"] = key
            except Exception as e:
                st.session_state["tts_audio"] = None
                st.warning(f"Nu am putut genera TTS: {e}")
        # dacÄƒ avem audio Ã®n cache, Ã®l redÄƒm la fiecare rerandare
        if st.session_state.get("tts_audio"):
            st.audio(st.session_state["tts_audio"], format="audio/mp3")